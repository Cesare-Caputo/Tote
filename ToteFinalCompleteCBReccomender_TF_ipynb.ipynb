{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP39i9OIEFUspL/XDc3vYGq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cesare-Caputo/Tote/blob/main/ToteFinalCompleteCBReccomender_TF_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWBsWLTGQT6c",
        "outputId": "374fc53b-4491-47b9-bcd0-60ff2420f00c"
      },
      "source": [
        "pip install pymongo[srv]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymongo[srv] in /usr/local/lib/python3.7/dist-packages (3.12.0)\n",
            "Collecting dnspython<2.0.0,>=1.16.0\n",
            "  Downloading dnspython-1.16.0-py2.py3-none-any.whl (188 kB)\n",
            "\u001b[K     |████████████████████████████████| 188 kB 26.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: dnspython\n",
            "Successfully installed dnspython-1.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL2xsSIjPxnQ",
        "outputId": "938b7163-cf2e-445c-93bb-1db55e667aa9"
      },
      "source": [
        "# Connect to Google Drive\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import Image, display\n",
        "from bson.json_util import dumps\n",
        "from pymongo import MongoClient\n",
        "from google.colab import drive\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction import text\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/Content-Based/dataframes/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNm_7LrfdGf6"
      },
      "source": [
        "#GALLERY FOR VISUALIZING EASIER\n",
        "from IPython.display import HTML, Image\n",
        "\n",
        "def _src_from_data(data):\n",
        "    \"\"\"Base64 encodes image bytes for inclusion in an HTML img element\"\"\"\n",
        "    img_obj = Image(data=data)\n",
        "    for bundle in img_obj._repr_mimebundle_():\n",
        "        for mimetype, b64value in bundle.items():\n",
        "            if mimetype.startswith('image/'):\n",
        "                return f'data:{mimetype};base64,{b64value}'\n",
        "\n",
        "def gallery(images, row_height='auto'):\n",
        "    \"\"\"Shows a set of images in a gallery that flexes with the width of the notebook.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    images: list of str or bytes\n",
        "        URLs or bytes of images to display\n",
        "\n",
        "    row_height: str\n",
        "        CSS height value to assign to all images. Set to 'auto' by default to show images\n",
        "        with their native dimensions. Set to a value like '250px' to make all rows\n",
        "        in the gallery equal height.\n",
        "    \"\"\"\n",
        "    figures = []\n",
        "    for image in images:\n",
        "        if isinstance(image, bytes):\n",
        "            src = _src_from_data(image)\n",
        "            caption = ''\n",
        "        else:\n",
        "            src = image\n",
        "            caption = f'<figcaption style=\"font-size: 0.6em\">{image}</figcaption>'\n",
        "        figures.append(f'''\n",
        "            <figure style=\"margin: 5px !important;\">\n",
        "              <img src=\"{src}\" style=\"height: {row_height}\">\n",
        "            </figure>\n",
        "        ''')\n",
        "    return HTML(data=f'''\n",
        "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
        "        {''.join(figures)}\n",
        "        </div>\n",
        "    ''')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmOZw1vYglCK"
      },
      "source": [
        "# Load Updated Items, Users, Interaction JSON files from Mongo DB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPsAjVQfvB5c"
      },
      "source": [
        "Note we have access to tagged items, users and interactions but only really need to retrieve items here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4A5_gmFxr5FA"
      },
      "source": [
        "# collection of non tagged items separately\n",
        "# Making Connection\n",
        "myclient = MongoClient(\n",
        "    \"mongodb+srv://Ethan:POkSdc0s8UWsHx47@totebackend.4gqwa.mongodb.net/ToteBackend?retryWrites=true&w=majority\")\n",
        "\n",
        "# getting database\n",
        "db = myclient[\"ToteBackend\"]\n",
        "# getting collection\n",
        "Item_Collection = db[\"items\"]\n",
        "\n",
        "# getting all tagged items\n",
        "item_cursor = Item_Collection.find({\"tagged\": False})\n",
        "item_lst = list(item_cursor)\n",
        "\n",
        "# using the JSON util import to convert to json, which is a list of dictionaries, each one is a tagged item\n",
        "item_json_data = dumps(item_lst)\n",
        "\n",
        "# writing to a file\n",
        "with open(root_dir + \"NottaggedItems.json\", \"w\") as f:\n",
        "    f.write(item_json_data)\n",
        "\n",
        "f.close()\n",
        "\n",
        "# getting all tagged items\n",
        "item_cursor = Item_Collection.find({\"tagged\":True})\n",
        "item_lst = list(item_cursor)\n",
        "\n",
        "# using the JSON util import to convert to json, which is a list of dictionaries, each one is a tagged item\n",
        "item_json_data = dumps(item_lst)\n",
        "\n",
        "# writing to a file\n",
        "with open(root_dir + \"taggedItems.json\", \"w\") as f:\n",
        "    f.write(item_json_data)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONFC-Ra4hNuB"
      },
      "source": [
        "# list them as individual dictionaries to access info later\n",
        "full_items = []\n",
        "items = []\n",
        "item_ids= []\n",
        "for line in open(root_dir + 'taggedItems.json', 'r'):\n",
        "    data = json.loads(line)\n",
        "    for item in range(len(data)):\n",
        "        items.append(data[item])\n",
        "        full_items.append(data[item])\n",
        "        item_ids.append(data[item]['_id']['$oid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I580V544sKJv"
      },
      "source": [
        "# list untagged items too to find them as individual dictionaries to access info later\n",
        "untagged_items = []\n",
        "for line in open(root_dir + 'NottaggedItems.json', 'r'):\n",
        "    data = json.loads(line)\n",
        "    for item in range(len(data)):\n",
        "        full_items.append(data[item])\n",
        "        untagged_items.append(data[item]['_id']['$oid'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD1bpA6ncXZB"
      },
      "source": [
        "# Define find_item() function\n",
        "def find_item(id):\n",
        " return next(item for item in full_items if item[\"_id\"][\"$oid\"] == id)\n",
        "# return list of unique items , useful for debuggin mostly\n",
        "def unpack_unique_reccs(idx):\n",
        "  s = []\n",
        "  for i in range(len(idx)):\n",
        "    s.append(idx[i])\n",
        "  return list(set(s))\n",
        "\n",
        "# function to flaten nested list of tags to input into DF\n",
        "def flatten(A):\n",
        "    rt = []\n",
        "    for i in A:\n",
        "        if isinstance(i,list): rt.extend(flatten(i))\n",
        "        else: rt.append(i)\n",
        "    return rt\n",
        "\n",
        "\n",
        "\n",
        "def list_of_tags_from_df(df):\n",
        "  all_tags_nested_list = []\n",
        "  for c in df.columns:\n",
        "    all_tags_nested_list.append(unpack_unique_reccs(df[c].value_counts().index))\n",
        "  all_tags_list = flatten(all_tags_nested_list)\n",
        "  return all_tags_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpeWPOd-H0A3"
      },
      "source": [
        "# Data Pre-Processing (Optional/ Periodic to avoid unnecessary computation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECkBDgt7OKgy"
      },
      "source": [
        "class MongoDBDataPreProcessing ():\n",
        "    def __init__(self, root_dir):\n",
        "      self.root_dir = root_dir # this is where all datafames preprocessed will be uploaded in csv file for retrieval later\n",
        "\n",
        "    def connect_and_write_json_user_item(self):\n",
        "      root_dir = self.root_dir\n",
        "      # Making Connection\n",
        "      myclient = MongoClient(\n",
        "          \"mongodb+srv://Ethan:POkSdc0s8UWsHx47@totebackend.4gqwa.mongodb.net/ToteBackend?retryWrites=true&w=majority\")\n",
        "\n",
        "      # getting database\n",
        "      db = myclient[\"ToteBackend\"]\n",
        "\n",
        "      # getting collection\n",
        "      Item_Collection = db[\"items\"]\n",
        "\n",
        "      # getting all tagged items\n",
        "      item_cursor = Item_Collection.find({\"tagged\": True})\n",
        "      item_lst = list(item_cursor)\n",
        "\n",
        "      # using the JSON util import to convert to json, which is a list of dictionaries, each one is a tagged item\n",
        "      item_json_data = dumps(item_lst)\n",
        "\n",
        "      # writing to a file\n",
        "      with open(root_dir + \"taggedItems.json\", \"w\") as f:\n",
        "          f.write(item_json_data)\n",
        "\n",
        "      f.close()\n",
        "\n",
        "      # getting users\n",
        "      User_Collection = db[\"users\"]\n",
        "\n",
        "      # getting all users with previous interactions\n",
        "      user_cursor = User_Collection.find({\"verified\": False})\n",
        "      user_lst = list(user_cursor)\n",
        "\n",
        "      # using the JSON util import to convert to json, which is a list of dictionaries, each one is a tagged item\n",
        "      user_json_data = dumps(user_lst)\n",
        "\n",
        "      # writing to a file\n",
        "      with open(root_dir + \"taggedUsers.json\", \"w\") as f:\n",
        "          f.write(user_json_data)\n",
        "\n",
        "      f.close()\n",
        "\n",
        "    def connect_and_write_json_interactions(self): # this one is kept seprate as we will want to update interactions much more than item tags\n",
        "      root_dir = self.root_dir\n",
        "      # Making Connection\n",
        "      myclient = MongoClient(\n",
        "          \"mongodb+srv://Ethan:POkSdc0s8UWsHx47@totebackend.4gqwa.mongodb.net/ToteBackend?retryWrites=true&w=majority\")\n",
        "\n",
        "      # getting database\n",
        "      db = myclient[\"ToteBackend\"]\n",
        "\n",
        "      # getting collection\n",
        "      Action_Collection = db[\"actions\"]\n",
        "\n",
        "      # getting all tagged items\n",
        "      action_cursor = Action_Collection.find({\"undone\": False})\n",
        "      action_lst = list(action_cursor)\n",
        "\n",
        "      # using the JSON util import to convert to json, which is a list of dictionaries, each one is a tagged item\n",
        "      action_json_data = dumps(action_lst)\n",
        "\n",
        "      # writing to a file\n",
        "      with open(root_dir + \"taggedActions.json\", \"w\") as f:\n",
        "          f.write(action_json_data)\n",
        "\n",
        "      f.close()\n",
        "\n",
        "    def unpack_json_into_dict_user_item(self):\n",
        "      root_dir = self.root_dir\n",
        "      self.connect_and_write_json_user_item() # call function to write files\n",
        "      # unpacking item tag databse\n",
        "      with open(root_dir +'taggedItems.json', 'r') as tag_df_dict:\n",
        "          item_df_data = json.load(tag_df_dict)\n",
        "\n",
        "      # now users\n",
        "\n",
        "      with open(root_dir +'taggedUsers.json', 'r') as users_df_dict:\n",
        "          users_df_data = json.load(users_df_dict)\n",
        "\n",
        "\n",
        "      return item_df_data, users_df_data\n",
        "\n",
        "\n",
        "    def unpack_json_into_dict_interaction(self):\n",
        "      root_dir = self.root_dir\n",
        "      self.connect_and_write_json_interactions()# call function to write files\n",
        "      # now interactions\n",
        "\n",
        "      with open(root_dir +'taggedActions.json', 'r') as action_df_dict:\n",
        "          action_df_data = json.load(action_df_dict)\n",
        "\n",
        "\n",
        "      return action_df_data\n",
        "\n",
        "\n",
        "    def create_dfs_user_item(self):\n",
        "      # Note that while quit long like this, it is sdone in one function to avoid unpakcing json multiple times\n",
        "      item_df_data,  users_df_data = self.unpack_json_into_dict_user_item()\n",
        "\n",
        "      ##### start with user db df ######\n",
        "      df = pd.DataFrame.from_dict(users_df_data)\n",
        "      # unpack user id from first columns\n",
        "      for i in range(len(df)):\n",
        "          user_sid = df['_id'][i]['$oid']\n",
        "          df['_id'][i] = user_sid\n",
        "\n",
        "      df.set_index(['_id'], inplace=True)\n",
        "      df.index.names = ['user_id']\n",
        "      # remove duplicates\n",
        "      df = df[~df.index.duplicated(keep='first')]\n",
        "\n",
        "      self.user_df = df\n",
        "\n",
        "      #### now item tag database##############\n",
        "      # # extract item tags to df\n",
        "      df1 = pd.DataFrame.from_dict(item_df_data)\n",
        "      # unpack item id from first columns\n",
        "      for i in range(len(df1)):\n",
        "          item_sid = df1['_id'][i]['$oid']\n",
        "          df1['_id'][i] = item_sid\n",
        "\n",
        "      df1.set_index(['_id'], inplace=True)\n",
        "      df1.index.names = ['item']\n",
        "      item_tag_df = df1.tags.apply(pd.Series)\n",
        "      for column in item_tag_df.columns:\n",
        "          item_tag_df = item_tag_df.explode(column)\n",
        "\n",
        "      item_tag_df.index.names = ['item']\n",
        "      #item_tag_df.reset_index(inplace = True)\n",
        "\n",
        "      item_tag_df.head()\n",
        "\n",
        "      #u##############npack description and genderinto separate df###########\n",
        "      df3 = df1[['description', 'gender' ]]\n",
        "      df3.index.names = ['item']\n",
        "\n",
        "      # remove duplicates\n",
        "      item_tag_df = item_tag_df[~item_tag_df.index.duplicated(keep='first')]\n",
        "      df3 = df3[~df3.index.duplicated(keep='first')]\n",
        "\n",
        "      # merge tags gender and description into full item df\n",
        "      full_item_df = pd.merge(item_tag_df, df3 , left_index=True, right_index=True)\n",
        "\n",
        "\n",
        "      #### now numerical item tax df############\n",
        "      # create reversen mapping item id to index in cosin sim matrix\n",
        "      index_values = list(range(len(item_tag_df)))\n",
        "      indices = pd.Series(index_values, index=item_tag_df.index).drop_duplicates()\n",
        "      # we are going to explode all tags recorded into individual columns to build this\n",
        "      all_tags_list = list_of_tags_from_df(item_tag_df)\n",
        "      columns = all_tags_list\n",
        "      columns_length = len(columns)\n",
        "      items_length = len(indices)\n",
        "\n",
        "      initialized_item_values = np.zeros((items_length), dtype=np.int)\n",
        "\n",
        "      item_tag_dict = dict.fromkeys(columns, initialized_item_values)\n",
        "\n",
        "      item_tax_df = pd.DataFrame(item_tag_dict, index = indices.index)\n",
        "\n",
        "      # update numerical item tax df with item tags\n",
        "      # NOTE THIS CAN BE LONG HENCE WHY ONLY NECESSARY FROM TIME TO TIME\n",
        "      item_ids = indices.index\n",
        "      for id in item_ids:\n",
        "        item_tags = item_tag_df.loc[id]\n",
        "        for column in item_tax_df.columns:\n",
        "          for tag in item_tags:\n",
        "            if tag == column:\n",
        "              item_tax_df.at[id, tag] = 1\n",
        "\n",
        "      # save within object\n",
        "      self.item_tag_df = item_tag_df\n",
        "      self.full_item_df = full_item_df\n",
        "      self.item_des_df = df3\n",
        "      self.full_item_scrape_df = df1\n",
        "      self.item_tax_df = item_tax_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def create_dfs_interactions(self):\n",
        "      action_df_data  = self.unpack_json_into_dict_interaction()\n",
        "      # extract actions to df\n",
        "\n",
        "      df2 = pd.DataFrame.from_dict(action_df_data)\n",
        "      df2.head()\n",
        "\n",
        "      # unpack item id from first columns\n",
        "      for i in range(len(df2)):\n",
        "          item_sid = df2['item'][i]['$oid']\n",
        "          user_sid = df2['user_id'][i]['$oid']\n",
        "          timestamp = df2['createdAt'][i]['$date']\n",
        "          df2['item'][i] = item_sid\n",
        "          df2['user_id'][i] = user_sid\n",
        "          df2['createdAt'][i] = timestamp\n",
        "\n",
        "      df2.set_index(['item'], inplace=True)\n",
        "\n",
        "      interaction_df = df2[[ \"user_id\" , \"createdAt\" , \"action\"]]\n",
        "\n",
        "\n",
        "\n",
        "      # ########### now convert to float values depending on interaction type and build user tag profile #############\n",
        "      # change rating to numerical, name columns with appropiate format\n",
        "      rank_df = interaction_df.replace(to_replace=\"LIKE\" , value =1)\n",
        "      rank_df = rank_df.replace(to_replace=\"DISLIKE\" , value =-1)\n",
        "      rank_df = rank_df.replace(to_replace=\"TO_CART\" , value =2)\n",
        "      rank_df = rank_df.replace(to_replace=\"REMOVE_FROM_CART\" , value =.5) # We assume this is negative here, but not as much as a full dislike since just changed their mind\n",
        "      rank_df['action'] = rank_df['action'].astype(float)\n",
        "\n",
        "      ###### and here create version with user ID indexing for easier retreival when building profile\n",
        "      user_id_interaction_df = rank_df.reset_index()\n",
        "      user_id_interaction_df.set_index('user_id',inplace =True)\n",
        "\n",
        "\n",
        "      ##### save within object #####\n",
        "\n",
        "      self.user_id_interaction_df = user_id_interaction_df\n",
        "      self.numerical_interaction_df = rank_df\n",
        "      self.interaction_df = interaction_df\n",
        "\n",
        "    def save_csv_2_drive_user_item(self):\n",
        "      root_dir = self.root_dir\n",
        "      self.create_dfs_user_item() # generate all dataframes from above\n",
        "      self.user_df.to_csv(root_dir + 'user_df.csv')\n",
        "      self.full_item_df.to_csv(root_dir + 'full_item_df.csv')\n",
        "      self.item_tag_df.to_csv(root_dir + 'item_tag_df.csv')\n",
        "      self.item_des_df.to_csv(root_dir + 'item_description_df.csv')\n",
        "      self.item_tax_df.to_csv(root_dir + 'item_tag_vector_df.csv')\n",
        "\n",
        "\n",
        "\n",
        "    def save_csv_2_drive_interactions(self):\n",
        "        root_dir = self.root_dir\n",
        "        self.create_dfs_interactions()\n",
        "        self.user_id_interaction_df.to_csv(root_dir + 'user_id_interaction_df.csv')\n",
        "        self.numerical_interaction_df.to_csv(root_dir + 'numerical_interaction_df.csv')\n",
        "        self.interaction_df.to_csv(root_dir + 'interaction_df.csv')\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csmbqlGhW6JE"
      },
      "source": [
        "# Load DFs from Datahandler Class (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAX6pm2LSalW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03b83e7-a6ca-4a83-f510-1118377d0644"
      },
      "source": [
        "data_handler = MongoDBDataPreProcessing(root_dir)\n",
        "data_handler.create_dfs_interactions()\n",
        "data_handler.create_dfs_user_item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:196: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:197: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:198: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luuGFvWIXCyY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c0a26b6-06a5-438a-9cd0-f7b076935669"
      },
      "source": [
        "# optional upload csv to drive if not being used live\n",
        "data_handler.save_csv_2_drive_interactions()\n",
        "data_handler.save_csv_2_drive_user_item()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:196: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:197: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:198: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:123: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpsAbP65di0j"
      },
      "source": [
        "# Acess all of them from data handler class\n",
        "# optional, can also do from drive or aws\n",
        "full_item_df = data_handler.full_item_df\n",
        "full_item_scrape_df = data_handler.full_item_scrape_df\n",
        "item_tag_df = data_handler.item_tag_df\n",
        "item_tax_df = data_handler.item_tax_df\n",
        "item_des_df = data_handler.item_des_df\n",
        "interaction_df = data_handler.interaction_df\n",
        "num_interaction_df = data_handler.numerical_interaction_df\n",
        "user_id_interaction_df = data_handler.user_id_interaction_df\n",
        "user_df = data_handler.user_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrXH0kh7aFhn"
      },
      "source": [
        "user_id_interaction_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfKVfasOaBm9"
      },
      "source": [
        "full_item_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aeyir0uT1VY"
      },
      "source": [
        "# Load DFs from drive (Optional if already created through data handler class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97Zfkgb4zSiG"
      },
      "source": [
        "This can be cleaned up slightly but is pretty fast since all computation happens offline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yDCVVUcT0lu"
      },
      "source": [
        "# Import CSVs as DFs from Drive\n",
        "# Note that some of these could be derived from the same but I import them separately to reduce computation time\n",
        "full_item_scrape_df = pd.read_csv(root_dir + 'full_item_scrape_df.csv') # tags and description\n",
        "full_item_df = pd.read_csv(root_dir + 'full_item_df.csv') # tags and description\n",
        "item_tag_df = pd.read_csv(root_dir + 'item_tag_df.csv') # string tags\n",
        "item_tax_df = pd.read_csv(root_dir + 'item_tag_vector_df.csv') # numerical vector tag representation\n",
        "item_des_df = pd.read_csv(root_dir + 'item_description_df.csv') # item id and description only for faster retreival\n",
        "interaction_df = pd.read_csv(root_dir + 'interaction_df.csv') # string interactions\n",
        "num_interaction_df = pd.read_csv(root_dir + 'numerical_interaction_df.csv') # float value interactions\n",
        "user_id_interaction_df = pd.read_csv(root_dir + 'user_id_interaction_df.csv') # user id index based interaction df\n",
        "user_df = pd.read_csv(root_dir + 'user_df.csv') # users information\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvtDB_aleiII"
      },
      "source": [
        "# reset index of all so it is aligned with ITEM ID\n",
        "# This is funciton of how pandas saves CSVs\n",
        "full_item_scrape_df.set_index(['item'], inplace = True)\n",
        "full_item_df.set_index(['item'], inplace = True)\n",
        "item_tag_df.set_index(['item'], inplace = True)\n",
        "item_tax_df.set_index(['item'], inplace = True)\n",
        "item_des_df.set_index(['item'], inplace = True)\n",
        "interaction_df.set_index(['item'], inplace = True)\n",
        "num_interaction_df.set_index(['item'], inplace = True)\n",
        "user_id_interaction_df.set_index(['user_id'], inplace = True)\n",
        "user_df.set_index(['user_id'], inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfwEPojr26LX"
      },
      "source": [
        "# Compute Item-Item similarity scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTBMgd1TZ0Ag"
      },
      "source": [
        "## TF-IDF description Scores ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwhaIRKUZ9f4"
      },
      "source": [
        "class TFIDF():\n",
        "    def __init__(self, item_description_df):\n",
        "        tfidf = TfidfVectorizer(stop_words =['french', 'english']) # not that while there are both english and french descriptions, they are approximately balanced for now so mathematically still able to do this within each language\n",
        "        self.item_description_df = item_description_df\n",
        "        # remove any invalid entries inccorectly imported\n",
        "        self.item_description_df['description'] = self.item_description_df['description'].fillna('')\n",
        "        self.tfidf_matrix = tfidf.fit_transform(self.item_description_df['description'])\n",
        "        self.cosine_sim_matrix = cosine_similarity(self.tfidf_matrix, self.tfidf_matrix)\n",
        "        # create reversen mapping item id to index in cosin sim matrix\n",
        "        self.index_values = list(range(len(self.item_description_df)))\n",
        "        self.indices = pd.Series(self.index_values, index=self.item_description_df.index).drop_duplicates()\n",
        "\n",
        "    def find_n_most_similar_items(self, item_id, n_items):\n",
        "        idx = self.indices[item_id]\n",
        "        # Get the pairwsie similarity scores of all items with this item ID\n",
        "        similarity_score = list(enumerate(self.cosine_sim_matrix[idx]))\n",
        "        # sort scores based on most similar\n",
        "        similarity_score = sorted(similarity_score, key=lambda x: x[1].all(), reverse=True)\n",
        "        # Get the scores of the 15 most similar items, ignoring first one.\n",
        "        similarity_score = similarity_score[1:n_items]\n",
        "        item_indices = [i[0] for i in similarity_score]\n",
        "        unique_recc_list = unpack_unique_reccs(self.item_description_df.iloc[item_indices].index)\n",
        "        return unique_recc_list\n",
        "\n",
        "    def gallery_n_most_similar_items(self, item_id, n_items):\n",
        "        top_n_reccs = self.find_n_most_similar_items(item_id, n_items)\n",
        "        image_urls =[]\n",
        "        for item_id in top_n_reccs:\n",
        "          item = find_item(item_id)\n",
        "          image_urls.append(item['header_img'])\n",
        "        unique_image_urls = list(set(image_urls))\n",
        "        return gallery(unique_image_urls, '200px')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffKwgySsdriQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "outputId": "5ee36343-e287-4d12-a649-b068c1d54fed"
      },
      "source": [
        "# test class just based on TFIDF\n",
        "similarities = TFIDF(item_des_df)\n",
        "test_item = str(full_item_df.sample().index[0])\n",
        "test_sim = similarities.find_n_most_similar_items(test_item, 20)\n",
        "print(test_sim)\n",
        "similarities.gallery_n_most_similar_items(test_item, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['5ffb7aa9f0206437132e2c52', '5faf4ce114d8b1415333928f', '5ffb7aa9f0206437132e2c9a', '5ff7a275eebdbd5e0a255549', '5ff7a333eebdbd5e0a25554a', '5ffb7aa9f0206437132e2c46', '5ff7a4e5eebdbd5e0a25554d', '5ffb7aa9f0206437132e2c66', '5ffb7aa9f0206437132e2c24', '5ff7a473eebdbd5e0a25554c', '5ffb7aa9f0206437132e2c1e', '5ffb7aa9f0206437132e2c2c', '5ffb7aa9f0206437132e2c4e', '5ffb7aa9f0206437132e2c84', '5ffb7aa9f0206437132e2c34', '5ffb7aa9f0206437132e2c90', '5ffb7aa9f0206437132e2c7e', '5ffb7aa9f0206437132e2c56', '5ffb7aa9f0206437132e2c76']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://images-na.ssl-images-amazon.com/images/I/81kD2Rfc-hL._AC_UY879_.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-ck3760_010-black__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://images-na.ssl-images-amazon.com/images/I/A1QBRDM4PaL._AC_UX679_.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://images-na.ssl-images-amazon.com/images/I/A1OsTjnyI3L._AC_UX679_.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-cj7740_011-black-red__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://images-na.ssl-images-amazon.com/images/I/51xXMuMJDML._AC_SX679_.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/h/a/haddad-36g217_a96-h-pink__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/e/centric-25uofdb04f_401-g-blue__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/u/n/under-1343622_002-black__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-cj7599_010-black__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/e/centric-25uofdb03s_023-blk-purple__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-bv2717_011-black__h19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-cu6608_100-white__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-cj7428_010-black__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-cj7870_010-black__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-858234_010-black__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://images-na.ssl-images-amazon.com/images/I/71XMFvF-ubL._AC_UX679_.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/e/centric-25uofdb04f_001-black__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "        </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIOkBztbhhgY"
      },
      "source": [
        "## Tag Based Item-Item similarity##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo6JtyLrgToV"
      },
      "source": [
        "class ItemTagSimilarity():\n",
        "    def __init__(self, item_tax_df):\n",
        "        self.item_tax_df = item_tax_df\n",
        "        self.item_tag_df = item_tag_df\n",
        "        self.tag_cosine_sim_matrix = cosine_similarity(self.item_tax_df, self.item_tax_df)\n",
        "        # create reversen mapping item id to index in cosin sim matrix tag and ensure same ones used as above\n",
        "        self.index_values = list(range(len(self.item_tag_df)))\n",
        "        self.indices = pd.Series(self.index_values, index=self.item_tag_df.index).drop_duplicates()\n",
        "\n",
        "    def find_n_most_similar_items(self, item_id, n_items):\n",
        "        idx = self.indices[item_id]\n",
        "        # Get the pairwsie similarity scores of all items with this item ID\n",
        "        similarity_score = list(enumerate(self.tag_cosine_sim_matrix[idx]))\n",
        "        # sort scores based on most similar\n",
        "        similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
        "        # Get the scores of the 15 most similar items, ignoring first one.\n",
        "        similarity_score = similarity_score[1:n_items]\n",
        "        item_indices = [i[0] for i in similarity_score]\n",
        "        unique_recc_list = unpack_unique_reccs(self.item_tax_df.iloc[item_indices].index)\n",
        "        return unique_recc_list\n",
        "\n",
        "    def gallery_n_most_similar_items(self, item_id, n_items):\n",
        "        top_n_reccs = self.find_n_most_similar_items(item_id, n_items)\n",
        "        image_urls =[]\n",
        "        for item_id in top_n_reccs:\n",
        "          item = find_item(item_id)\n",
        "          image_urls.append(item['header_img'])\n",
        "        unique_image_urls = list(set(image_urls))\n",
        "        return gallery(unique_image_urls, '200px')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRxtAP9YRm4z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "57a0745d-b7ff-4ba6-dbc3-7c7fbdd67c1f"
      },
      "source": [
        "# initiale class and test functions\n",
        "tag_similarities = ItemTagSimilarity(item_tax_df)\n",
        "test_item = str(full_item_df.sample().index[0])\n",
        "print(test_item)\n",
        "tag_similarities.find_n_most_similar_items(test_item, 20)\n",
        "most_sim = tag_similarities.find_n_most_similar_items(test_item, 20)\n",
        "tag_similarities.gallery_n_most_similar_items(test_item, 20)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5ffb7b8daf0a8d378f48d838\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1533781_010-black__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/e/newbalan-ms01241_snb-s-blue__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/p/a/patagonia-57736_chnn-neo-navy__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/u/n/under-1344552_090-carbon-h__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/o/northfac-nf0a2uo7_7d0-new-taupe__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/o/northfac-nf0a48ux_21l-new-taupe__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/m/o/momentum-t2312912_940-high-tide__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/416wIUf3ndL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/s/m/smartwoo-sw016250_001-black__h19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/o/northfac-nf0a3xg5_jk3-tnf-black__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31nTloYoQ7L.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/314PXXfwsQL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/j/c/jcorp-ts7xav937_night-olive__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-cj2299_010-black__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-aj5493_072-light-bone__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/a/r/arcter-23068_dracaena__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/o/northfac-nf0a4aqf_h2g-urban-navy__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "        </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miNWBW3SjN-J"
      },
      "source": [
        "## Weighted Taxonpomy tags/ TFIDF similarity##\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHLbmTiXHZjG"
      },
      "source": [
        "class WeighedItemSimilarity():\n",
        "    def __init__(self, item_description_df, item_tax_df , w_tfidf, w_tax):\n",
        "        self.item_tax_df = item_tax_df\n",
        "        self.item_description_df = item_description_df\n",
        "        self.w_tfidf = w_tfidf # weight assigned to tfidf similarit\n",
        "        self.w_tax = w_tax # weight assigned item tag similarity\n",
        "        self.tagged_items_list = list(self.item_tax_df.index)\n",
        "\n",
        "\n",
        "        # create reversen mapping item id to index in cosin sim matrix tag and ensure same ones used as above\n",
        "        # Can use eithe ror as using item id as index helps ensure consistenct here\n",
        "        self.index_values = list(range(len(self.item_tax_df)))\n",
        "        self.indices = pd.Series(self.index_values, index=self.item_tax_df.index).drop_duplicates()\n",
        "\n",
        "        # Acess classes from above and similarity matrices produced\n",
        "        self.tfidf_similarity = TFIDF(self.item_description_df)\n",
        "        self.tag_similarity = ItemTagSimilarity(self.item_tax_df)\n",
        "\n",
        "        # Access simlarity matrices\n",
        "        self.tfidf_cosine_sim = self.tfidf_similarity.cosine_sim_matrix\n",
        "        self.tag_cosine_sim = self.tag_similarity.tag_cosine_sim_matrix\n",
        "\n",
        "    def weighed_sim_scorer(self, item_id):\n",
        "      idx = self.indices[item_id]\n",
        "      # Get the pairwsie similarity scores of all items with this item ID\n",
        "      # Separate TFIDF and Tags for now\n",
        "      similarity_score_tfidf = list(enumerate(self.tfidf_cosine_sim[idx]))\n",
        "      similarity_score_tags = list(enumerate(self.tag_cosine_sim[idx]))\n",
        "\n",
        "      self.weighed_sim_score =pd.Series(index = self.indices)\n",
        "      for i in range(len(self.indices)):\n",
        "        self.weighed_sim_score[i] = self.w_tfidf* similarity_score_tfidf[i][1] + self.w_tax * similarity_score_tags[i][1]\n",
        "\n",
        "      self.weighed_sim_score = list(enumerate(self.weighed_sim_score))\n",
        "      self.weighed_sim_score = sorted(self.weighed_sim_score, key=lambda x: x[1], reverse=True)\n",
        "      return self.weighed_sim_score\n",
        "\n",
        "    def all_weighed_sim_scores(self):\n",
        "      for item in self.tagged_items_list:\n",
        "        idx = self.indices[item]\n",
        "        # Get the pairwsie similarity scores of all items with this item ID\n",
        "        # Separate TFIDF and Tags for now\n",
        "        similarity_score_tfidf = list(enumerate(self.tfidf_cosine_sim[idx]))\n",
        "        similarity_score_tags = list(enumerate(self.tag_cosine_sim[idx]))\n",
        "\n",
        "        self.all_weighed_sim_score =pd.Series(index = self.indices)\n",
        "        for i in range(len(self.indices)):\n",
        "          self.all_weighed_sim_score[i] = self.w_tfidf* similarity_score_tfidf[i][1] + self.w_tax * similarity_score_tags[i][1]\n",
        "\n",
        "      self.all_weighed_sim_score = list(enumerate(self.all_weighed_sim_score))\n",
        "      self.all_weighed_sim_score = sorted(self.all_weighed_sim_score, key=lambda x: x[1], reverse=True)\n",
        "      return self.all_weighed_sim_score\n",
        "\n",
        "    def find_n_most_similar_items(self, item_id, n_items):\n",
        "        weighed_sim_score = self.weighed_sim_scorer(item_id)\n",
        "        weighed_sim_score = weighed_sim_score[1:n_items]\n",
        "        item_indices = [i[0] for i in weighed_sim_score]\n",
        "        unique_recc_list = unpack_unique_reccs(self.item_tax_df.iloc[item_indices].index)\n",
        "        return unique_recc_list\n",
        "\n",
        "    def gallery_n_most_similar_items(self, item_id, n_items):\n",
        "        top_n_reccs = self.find_n_most_similar_items(item_id, n_items)\n",
        "        image_urls =[]\n",
        "        for item_id in top_n_reccs:\n",
        "          item = find_item(item_id)\n",
        "          image_urls.append(item['header_img'])\n",
        "        unique_image_urls = list(set(image_urls))\n",
        "        return gallery(unique_image_urls, '200px')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "E5mV00j6mMQj",
        "outputId": "31251047-4660-4588-d61d-63a66ff070ad"
      },
      "source": [
        "# test class\n",
        "w_tfidf = .2 # weight assignd to tifidf descriptions\n",
        "w_tags = .8 # weight assigned to item tag similarity scores\n",
        "comb_similarities = WeighedItemSimilarity(item_des_df, item_tax_df , w_tfidf, w_tags)\n",
        "test_item = str(full_item_df.sample().index[0])\n",
        "test_sim = comb_similarities.find_n_most_similar_items(test_item, 20)\n",
        "comb_similarities.gallery_n_most_similar_items(test_item, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/r/o/royalrob-43019_568-asphalt__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/p/a/patagonia-57736_chnn-neo-navy__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1441701_464-collegiate__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1441706_160-fossil__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/q/u/quicksil-eqmws03078_sew0-rainy-day__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1883281_023-city-grey__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/r/o/royalrob-y33120_622-stellar__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31hLtMEQQKL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/s/a/saltycrew-30435024_charcoal__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/319XWBWMExL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/o/northfac-nf0a4apc_zdl-t-beige__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/k/u/kuhl-5230_storm-khaki__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1441706-10_028-g.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/p/a/patagonia-57826_fge-forge-grey__s19.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1491953_464-c-navy__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1441706_464-collegiate__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "        </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3uM3e5v3idJ"
      },
      "source": [
        "# User Preference Elicitation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0PxMfnQRSNd"
      },
      "source": [
        "# Collect all users registered for testing reccs produced and initial preference elicitation\n",
        "test_users = []\n",
        "for i in range(len(list(user_df.index))):\n",
        "  test_users.append(user_df.index[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VseTytovm10i"
      },
      "source": [
        "## Gender Based ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykSGGh6E3Yna"
      },
      "source": [
        "This class generated initial reccs simply based on gender, in case there any errors rettriewivng gender form Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5DU3vvjm6CN"
      },
      "source": [
        "class UserGenderPreferenceElictation():\n",
        "    def __init__(self, user_gender, item_tag_df, full_item_df):\n",
        "      self.item_tag_df = item_tag_df\n",
        "      self.user_gender = user_gender\n",
        "      self.full_item_df = full_item_df\n",
        "      # here split into different category dfs and select some at random to initialize user profile\n",
        "      # only going to do this with categories with 5 most items as those most central to reccs, will extend later\n",
        "      # also makes it easy as we just pick 5 from each\n",
        "      self.bottoms_df = self.item_tag_df[self.item_tag_df['category'] =='bottoms']\n",
        "      self.tops_df = self.item_tag_df[self.item_tag_df['category'] =='tops']\n",
        "      self.outerwear_df = self.item_tag_df[self.item_tag_df['category'] =='outerwear']\n",
        "      self.dj_df = self.item_tag_df[self.item_tag_df['category'] =='dresses & jumpsuits']\n",
        "\n",
        "\n",
        "    # gender of 1 is male , 2 is female\n",
        "    # looks like they are not always properly labeled when being scraped\n",
        "    # could maybe have taggers do this too? should be very quick for them\n",
        "    # there is even dressed coming up tagged as male items....\n",
        "    # will also later add addiitonal filter to ensure intraitem similarity below treshold\n",
        "    def generate_initial_items(self):\n",
        "      #df1 = self.full_item_df\n",
        "      # generate initial 50 candidates for each candidate, then filter to make sure correct gender\n",
        "      self.samples_per_cat = 50\n",
        "      bottoms_candidates = self.bottoms_df.sample( n= self.samples_per_cat).index\n",
        "      tops_candidates = self.tops_df.sample( n= self.samples_per_cat).index\n",
        "      outerwear_candidates = self.outerwear_df.sample( n= self.samples_per_cat).index\n",
        "      dj_candidates = self.dj_df.sample( n= self.samples_per_cat).index\n",
        "      # iterate over candidates to filter out wrong gender\n",
        "      self.filtered_bottoms =[]\n",
        "      self.filtered_tops = []\n",
        "      self.filtered_outerwear =[]\n",
        "      self.filtered_dj =[]\n",
        "      for i in range(self.samples_per_cat):\n",
        "        bid = bottoms_candidates[i]\n",
        "        tid = tops_candidates[i]\n",
        "        oid = outerwear_candidates[i]\n",
        "        djid = dj_candidates[i]\n",
        "        if self.full_item_df['gender'][bid] == self.user_gender:\n",
        "          self.filtered_bottoms.append(bid)\n",
        "        if self.full_item_df['gender'][tid] == self.user_gender:\n",
        "          self.filtered_tops.append(tid)\n",
        "        if self.full_item_df['gender'][oid] == self.user_gender:\n",
        "          self.filtered_outerwear.append(oid)\n",
        "        if self.full_item_df['gender'][djid] == self.user_gender:\n",
        "          self.filtered_dj.append(djid)\n",
        "\n",
        "    # pick a few from top of each list, randomly rampled at the top to ensure not everyone getting same ones\n",
        "      if self.user_gender == [2]: # aka female so include dresses and jumpsuits in initial selection\n",
        "        self.selected_candidates = self.filtered_bottoms[1:5] + self.filtered_tops[1:5] + self.filtered_outerwear[1:5] + self.filtered_dj[1:5] #+ filtered_underwear[1:1]\n",
        "      else: self.selected_candidates = self.filtered_bottoms[1:7] + self.filtered_tops[1:7] + self.filtered_outerwear[1:6]\n",
        "      return self.selected_candidates\n",
        "\n",
        "    def gallery_initial_items(self):\n",
        "      initial_items_list = self.generate_initial_items()\n",
        "      image_urls =[]\n",
        "      for item_id in initial_items_list:\n",
        "        item = find_item(item_id)\n",
        "        image_urls.append(item['header_img'])\n",
        "      return gallery(image_urls, '200px')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHL9AvKun9z0"
      },
      "source": [
        "# test classs\n",
        "recstart = UserGenderPreferenceElictation('[2]' , item_tag_df, full_item_df)\n",
        "a = recstart.generate_initial_items()\n",
        "recstart.gallery_initial_items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f--pGcCQmXoX"
      },
      "source": [
        "## USER ID  Based##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPZaK3EsIERr"
      },
      "source": [
        "# this version uses user_id to retrieve gender but there seems to be a lot of incosistencies in backend which make this diffuclt in practice, such as missing user_ids or genders 0\n",
        "# Note that if gender from dF not recognized, defaults to female as we will have more of those users plus lots of male items too tagged as female so get nice mix\n",
        "class UserIdPreferenceElictation():\n",
        "    def __init__(self, user_id, user_df, item_tag_df, full_item_df):\n",
        "      self.item_tag_df = item_tag_df\n",
        "      self.user_df = user_df\n",
        "      self.user_id = user_id\n",
        "      self.full_item_df = full_item_df\n",
        "\n",
        "      self.listed_user_ids = list(self.user_df.index)\n",
        "      # note that this does not work with all user IDs yet because of some incosistencyy on the back end...\n",
        "      # ones in user df it works for but also sometimes gender listed weirdly\n",
        "      if self.user_id in self.listed_user_ids:\n",
        "        acceptable_genre_entries = ['[1]','[2]']\n",
        "        df_gender = self.user_df.loc[self.user_id]['gender']\n",
        "        # convert to format suitable for retrieving\n",
        "        if df_gender ==2.0:\n",
        "          self.user_gender = '[2]'\n",
        "        elif df_gender ==1.0:\n",
        "          self.user_gender = '[1]'\n",
        "        else:\n",
        "          self.user_gender = '[2]' # mostly we will have girls\n",
        "      else: self.user_gender = '[2]'\n",
        "\n",
        "      # here split into different category dfs and select some at random to initialize user profile\n",
        "      # only going to do this with categories with 5 most items as those most central to reccs, will extend later\n",
        "      # also makes it easy as we just pick 5 from each\n",
        "      self.bottoms_df = self.item_tag_df[self.item_tag_df['category'] =='bottoms']\n",
        "      self.tops_df = self.item_tag_df[self.item_tag_df['category'] =='tops']\n",
        "      self.outerwear_df = self.item_tag_df[self.item_tag_df['category'] =='outerwear']\n",
        "      self.dj_df = self.item_tag_df[self.item_tag_df['category'] =='dresses & jumpsuits']\n",
        "      self.underwear_df = self.item_tag_df[self.item_tag_df['category'] =='underwear']\n",
        "\n",
        "\n",
        "    # gender of 1 is male , 2 is female\n",
        "    # looks like they are not always properly labeled when being scraped\n",
        "    # could maybe have taggers do this too? should be very quick for them\n",
        "    # could also add additional filter saying ITESMS CANNOT BE IN TOP 10 MOST SIMILAR TO ANOTHER TO ADD DIVERSITY\n",
        "    def generate_initial_items(self):\n",
        "      #df1 = self.full_item_df\n",
        "      # generate initial 50 candidates for each candidate, then filter to make sure correct gender\n",
        "      self.samples_per_cat = 20\n",
        "      bottoms_candidates = self.bottoms_df.sample( n= np.min([self.samples_per_cat, len(self.bottoms_df)])).index\n",
        "      tops_candidates = self.tops_df.sample( n= np.min([self.samples_per_cat, len(self.tops_df)])).index\n",
        "      outerwear_candidates = self.outerwear_df.sample( n= np.min([self.samples_per_cat, len(self.outerwear_df)])).index\n",
        "      dj_candidates = self.dj_df.sample( n= np.min([self.samples_per_cat, len(self.dj_df)])).index\n",
        "      # iterate over candidates to filter out wrong gender\n",
        "      self.filtered_bottoms =[]\n",
        "      self.filtered_tops = []\n",
        "      self.filtered_outerwear =[]\n",
        "      self.filtered_dj =[]\n",
        "      for i in range(self.samples_per_cat):\n",
        "        bid = bottoms_candidates[i]\n",
        "        tid = tops_candidates[i]\n",
        "        oid = outerwear_candidates[i]\n",
        "        djid = dj_candidates[i]\n",
        "        if  self.full_item_df['gender'][bid] == self.user_gender:\n",
        "          self.filtered_bottoms.append(bid)\n",
        "        if  self.full_item_df['gender'][tid] == self.user_gender:\n",
        "          self.filtered_tops.append(tid)\n",
        "        if self.full_item_df['gender'][oid] == self.user_gender:\n",
        "          self.filtered_outerwear.append(oid)\n",
        "        if self.full_item_df['gender'][djid] == self.user_gender:\n",
        "          self.filtered_dj.append(djid)\n",
        "\n",
        "    # pick a few from top of each list, randomly rampled at the top to ensure not everyone getting same ones\n",
        "    # there is even dressed coming up tagged as male items....\n",
        "      #self.total_filtered_candidates = self.filtered_bottoms + self.filtered_tops + self.filtered_outwerwear + self.filtered_dj\n",
        "      if self.user_gender == [2]: # aka female so include dresses and jumpsuits\n",
        "        self.selected_candidates = self.filtered_bottoms[1:5] + self.filtered_tops[1:5] + self.filtered_outerwear[1:5] + self.filtered_dj[1:5] #+ filtered_underwear[1:1]\n",
        "      else: self.selected_candidates = self.filtered_bottoms[1:7] + self.filtered_tops[1:7] + self.filtered_outerwear[1:6]\n",
        "      return self.selected_candidates\n",
        "\n",
        "    def gallery_initial_items(self):\n",
        "      initial_items_list = self.generate_initial_items()\n",
        "      image_urls =[]\n",
        "      for item_id in initial_items_list:\n",
        "        item = find_item(item_id)\n",
        "        image_urls.append(item['header_img'])\n",
        "      return gallery(image_urls, '200px')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "XuehQrPYnLwS",
        "outputId": "a59022c0-bcf7-4043-c538-65f68c2eadca"
      },
      "source": [
        "random_user = random.choice(test_users)\n",
        "print(\"user gender is\")\n",
        "print(user_df.loc[random_user])\n",
        "recstart_id = UserIdPreferenceElictation(random_user , user_df, item_tag_df, full_item_df)\n",
        "test_reccs = recstart_id.generate_initial_items()\n",
        "recstart_id.gallery_initial_items()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user gender is\n",
            "credit_card                {'name': '', 'number': '', 'cvs': '', 'expiry'...\n",
            "shipping_address           {'street_number': '', 'street_name': '', 'city...\n",
            "billing_address            {'street_number': '', 'street_name': '', 'city...\n",
            "device_id                                                                NaN\n",
            "name                                                                   Guest\n",
            "email                                   FDEC00DB-B69C-4839-A3D3-4C757F05B413\n",
            "country                                                                  NaN\n",
            "phone_number                                                             NaN\n",
            "avatar                                                                   NaN\n",
            "gender                                                                     1\n",
            "date_of_birth                                                            NaN\n",
            "password                                    b1aaed3273ab7a63d8c3a61d08a8abc7\n",
            "access_level                                                               1\n",
            "invite_user_code                                                         NaN\n",
            "social_auth                                                            False\n",
            "payment_method                                                         False\n",
            "verified                                                               False\n",
            "is_billing_address_same                                                False\n",
            "createdAt                                           {'$date': 1608576660794}\n",
            "updatedAt                                           {'$date': 1616575270245}\n",
            "__v                                                                        0\n",
            "token                                                                    NaN\n",
            "Name: 5fe0ee9498d79d00170a38e5, dtype: object\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31DTs2WsifL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31hLtMEQQKL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/41dmQ6--auL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31Ai1PYa3XL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31-HdOt6kKL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/41T0xH4SW6L.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/51SxO8xdWLL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31tBXGptp3L.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31kCcZpKNEL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/41W-oB4jUvL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/41+rCgna0HL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/41WYcU1TbuL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/316ueaZITTL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/31Bzlod9iZL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"https://m.media-amazon.com/images/I/41ZQdRZCXEL.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "        </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfuXq8rToySj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff9769eb-3f72-4edf-adba-6223675817ea"
      },
      "source": [
        "# further confirmation incorrecat gender tagging of both users and items\n",
        "# Even tho all items come as same gender there is some obviously wrong ones\n",
        "print(user_df.loc[random_user]['gender'])\n",
        "for i in test_reccs:\n",
        "  print(full_item_scrape_df.loc[i]['gender'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n",
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHXPRxPxVBo3"
      },
      "source": [
        "# User Profile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpSj0FGpzWE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73763c34-3942-47bb-bf12-42bc00a4df12"
      },
      "source": [
        "# identify \"old\" user with more than 20 interactions or \"new ones\"\n",
        "old_users = []\n",
        "new_users = []\n",
        "test_interacted_users = list(user_id_interaction_df.index)\n",
        "for user in test_interacted_users:\n",
        "   udf = user_id_interaction_df.loc[user]\n",
        "   if len (udf)>19:\n",
        "     old_users.append(user)\n",
        "   else: new_users.append(user)\n",
        "\n",
        "print(\"New users\" , len(new_users ))\n",
        "print(\"Old users\" , len(old_users))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New users 32\n",
            "Old users 192\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTjYrSSRVBAg"
      },
      "source": [
        "# issues with fact that lots of items interacted with not yet tatgged, this should not happen and be filtered befroee\n",
        "# Will also add class to calculate most liked features by user\n",
        "class UserProfile():\n",
        "    def __init__(self, user_id, user_df, item_tag_df, item_des_df, item_tax_df , user_id_interaction_df):\n",
        "      self.item_tag_df = item_tag_df\n",
        "      self.user_df = user_df\n",
        "      self.user_id = user_id\n",
        "      self.item_des_df = item_des_df\n",
        "      self.item_tax_df = item_tax_df\n",
        "      self.user_int_df = user_id_interaction_df\n",
        "      self.tagged_items_list = list(self.item_tax_df.index)\n",
        "\n",
        "    def user_profile_dict_creator(self):\n",
        "        self.user_id_int_df = self.user_int_df.loc[self.user_id] # retrieve interactions for user\n",
        "        self.rank_df = self.user_id_int_df.reset_index()\n",
        "        self.rank_df.set_index('item', inplace = True)\n",
        "        self.ranked_items = list(self.rank_df.index)\n",
        "        self.rankings = list(self.rank_df.action)\n",
        "\n",
        "        # initiate user profile dictionary\n",
        "        columns = list(self.item_tax_df.columns)\n",
        "        user_profile = dict.fromkeys(columns, 0)\n",
        "        for item in self.ranked_items:\n",
        "          if item in self.tagged_items_list: # no meaning in creating vectors for items not tagged\n",
        "            item_profile = self.item_tag_df.loc[item]\n",
        "            item_tag_indexes = list(item_profile.dropna().values)\n",
        "            for tag in item_tag_indexes:\n",
        "              invalid_tags = ['nan' , 'n/a', None]\n",
        "              if tag not in invalid_tags:\n",
        "                tag_value = self.rank_df.loc[item]['action'].mean() # we take the mean across interactions for this item\n",
        "                user_profile[tag] = user_profile[tag] + tag_value\n",
        "\n",
        "        self.user_profile_filled = user_profile\n",
        "\n",
        "        return user_profile\n",
        "\n",
        "\n",
        "    def create_user_scores_df(self):\n",
        "      self.user_profile_dict_filled = self.user_profile_dict_creator()\n",
        "      self.user_scores_df = pd.DataFrame(self.user_profile_dict_filled , index = [self.user_id])\n",
        "      return self.user_scores_df\n",
        "\n",
        "\n",
        "    def create_user_tag_value_vector(self):\n",
        "      self.user_scores_df = self.create_user_scores_df()\n",
        "      self.user_tag_value_vector =  np.asarray(self.user_scores_df)\n",
        "      return self.user_tag_value_vector\n",
        "\n",
        "\n",
        "    def calculate_all_item_scores(self):\n",
        "      self.user_tag_value_vector = self.create_user_tag_value_vector()\n",
        "\n",
        "      from collections import OrderedDict\n",
        "\n",
        "      self.scores_by_item = {}\n",
        "      self.scores = []\n",
        "\n",
        "      item_ids_list = list(self.item_tax_df.index)\n",
        "      for item in item_ids_list:\n",
        "        item_tag_vector = self.item_tax_df.loc[item].to_numpy()\n",
        "        score = np.dot(self.user_tag_value_vector, item_tag_vector)\n",
        "        self.scores_by_item[item] = score\n",
        "        self.scores.append(score)\n",
        "\n",
        "      return self.scores_by_item, self.scores\n",
        "\n",
        "    def retrieve_positive_items(self):\n",
        "      self.user_profile_dict = self.user_profile_dict_creator()\n",
        "      positive_items = []\n",
        "      for item in self.ranked_items:\n",
        "        if self.rank_df.loc[item]['action'].mean() > 0:\n",
        "          positive_items.append(item)\n",
        "      self.positive_items = positive_items\n",
        "      return self.positive_items\n",
        "\n",
        "    def retrieve_ranked_items(self):\n",
        "        self.user_id_int_df = self.user_int_df.loc[self.user_id] # retrieve interactions for user\n",
        "        self.rank_df = self.user_id_int_df.reset_index()\n",
        "        self.rank_df.set_index('item', inplace = True)\n",
        "        self.ranked_items = list(self.rank_df.index)\n",
        "        self.rankings = list(self.rank_df.action)\n",
        "        return self.ranked_items\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8w7fRxnVwWV"
      },
      "source": [
        "# A lot of users will have empty profiles sinc enot itneracted with TAGGED ITEMS\n",
        "random_test_user = random.choice(old_users)\n",
        "user_profile = UserProfile(random_test_user, user_df, item_tag_df,  item_des_df, item_tax_df , user_id_interaction_df)\n",
        "user_all_item_scores_by_item , user_item_scores = user_profile.calculate_all_item_scores()\n",
        "user_liked_items = user_profile.retrieve_positive_items()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_igzRQVrbIUN"
      },
      "source": [
        "This code below confirms there is lots of items being shown that are not tagged yet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tZKajEubbPF",
        "outputId": "a4abc6bb-dd08-4d7d-c839-82daf7539687"
      },
      "source": [
        "# look at interacted items for all users recorded and compare sizes\n",
        "interacted_items = []\n",
        "users_with_interactions = old_users +new_users\n",
        "for i in (users_with_interactions):\n",
        "  iid = list(user_id_interaction_df.loc[i]['item'])\n",
        "  interacted_items.append(iid)\n",
        "\n",
        "k = flatten(list(interacted_items))\n",
        "\n",
        "tagged_items = list(item_tag_df.index)\n",
        "\n",
        "user_int_tagged = []\n",
        "user_int_na_tagged = []\n",
        "for item in k: #\n",
        "  if item in tagged_items:\n",
        "    user_int_tagged.append(item)\n",
        "  else: user_int_na_tagged.append(item)\n",
        "\n",
        "unique_int_tagged = list(set(user_int_tagged))\n",
        "unique_int_na_tagged = list(set(user_int_na_tagged))\n",
        "\n",
        "print(\"Out of recorded interactions\", len(user_int_tagged), \"are tagged while not tagged are\" , len(user_int_na_tagged))\n",
        "# Out of all recorded u\n",
        "print(\"unique tagged\" , len(unique_int_tagged))\n",
        "print(\"unique not tagged\" , len(unique_int_na_tagged))\n",
        "print(\"total unique items shown\",  len(unique_int_tagged) + len(unique_int_na_tagged))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out of recorded interactions 7 are tagged while not tagged are 8355\n",
            "unique tagged 1\n",
            "unique not tagged 31\n",
            "total unique items shown 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z312ImIn2k49"
      },
      "source": [
        "# Final CB Reccomender"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hurR5j7P1LE7"
      },
      "source": [
        "class FinalToteCBReccomenderDriveItem():\n",
        "    def __init__(self, user_id, update_interactions, update_items, root_dir, w_tfidf, w_tax):\n",
        "\n",
        "      self.root_dir = root_dir\n",
        "      self.data_handler = MongoDBDataPreProcessing(root_dir)\n",
        "      self.user_id = user_id\n",
        "      self.w_tfidf = w_tfidf\n",
        "      self.w_tax = w_tax\n",
        "\n",
        "\n",
        "      if update_interactions == True:\n",
        "        if update_items == True:\n",
        "        # Instantiate Data handler class first to retrieve updated interaction DF.\n",
        "          self.data_handler = MongoDBDataPreProcessing(root_dir)\n",
        "          self.data_handler.create_dfs_interactions()\n",
        "          self.data_handler.save_csv_2_drive_interactions()\n",
        "          self.data_handler.save_csv_2_drive_user_item()\n",
        "\n",
        "          self.user_id_interaction_df = self.data_handler.user_id_interaction_df\n",
        "          # load rmeaining ones from drive or other storage directory\n",
        "          self.full_item_df = pd.read_csv(root_dir + 'full_item_df.csv') # tags and description\n",
        "          self.item_tag_df = pd.read_csv(root_dir + 'item_tag_df.csv') # string tags\n",
        "          self.item_tax_df = pd.read_csv(root_dir + 'item_tag_vector_df.csv') # numerical vector tag representation\n",
        "          self.item_des_df = pd.read_csv(root_dir + 'item_description_df.csv') # item id and description only for faster retreival\n",
        "          self.interaction_df = pd.read_csv(root_dir + 'interaction_df.csv') # string interactions\n",
        "          self.num_interaction_df = pd.read_csv(root_dir + 'numerical_interaction_df.csv') # float value interactions\n",
        "          self.user_df = pd.read_csv(root_dir + 'user_df.csv') # users information\n",
        "        else:\n",
        "          # Instantiate Data handler class first to retrieve updated interaction DF.\n",
        "          self.data_handler = MongoDBDataPreProcessing(root_dir)\n",
        "          self.data_handler.create_dfs_interactions()\n",
        "          self.user_id_interaction_df = self.data_handler.user_id_interaction_df\n",
        "          # load rmeaining ones from drive or other storage directory\n",
        "          self.full_item_df = pd.read_csv(root_dir + 'full_item_df.csv') # tags and description\n",
        "          self.item_tag_df = pd.read_csv(root_dir + 'item_tag_df.csv') # string tags\n",
        "          self.item_tax_df = pd.read_csv(root_dir + 'item_tag_vector_df.csv') # numerical vector tag representation\n",
        "          self.item_des_df = pd.read_csv(root_dir + 'item_description_df.csv') # item id and description only for faster retreival\n",
        "          self.interaction_df = pd.read_csv(root_dir + 'interaction_df.csv') # string interactions\n",
        "          self.num_interaction_df = pd.read_csv(root_dir + 'numerical_interaction_df.csv') # float value interactions\n",
        "          self.user_df = pd.read_csv(root_dir + 'user_df.csv' ) # users information\n",
        "\n",
        "\n",
        "      else: # load all of them from drive\n",
        "        self.full_item_df = pd.read_csv(root_dir + 'full_item_df.csv') # tags and description\n",
        "        self.item_tag_df = pd.read_csv(root_dir + 'item_tag_df.csv') # string tags\n",
        "        self.item_tax_df = pd.read_csv(root_dir + 'item_tag_vector_df.csv') # numerical vector tag representation\n",
        "        self.item_des_df = pd.read_csv(root_dir + 'item_description_df.csv') # item id and description only for faster retreival\n",
        "        self.interaction_df = pd.read_csv(root_dir + 'interaction_df.csv') # string interactions\n",
        "        self.num_interaction_df = pd.read_csv(root_dir + 'numerical_interaction_df.csv') # float value interactions\n",
        "        self.user_id_interaction_df = pd.read_csv(root_dir + 'user_id_interaction_df.csv') # user id index based interaction df\n",
        "        self.user_df = pd.read_csv(root_dir + 'user_df.csv') # users information\n",
        "\n",
        "        # this one only applied if loaded from drive as otherwise is properly indexed already through data handler class\n",
        "        self.user_id_interaction_df.set_index(['user_id'], inplace = True)\n",
        "\n",
        "  ### reset indexes on dataframes to item and user ids\n",
        "\n",
        "  # reset index of all so it is aligned with ITEM ID\n",
        "      # This is funciton of how pandas saves CSVs\n",
        "      self.full_item_df.set_index(['item'], inplace = True)\n",
        "      self.item_tag_df.set_index(['item'], inplace = True)\n",
        "      self.item_tax_df.set_index(['item'], inplace = True)\n",
        "      self.item_des_df.set_index(['item'], inplace = True)\n",
        "      self.interaction_df.set_index(['item'], inplace = True)\n",
        "      self.num_interaction_df.set_index(['item'], inplace = True)\n",
        "      self.user_df.set_index(['user_id'], inplace = True)\n",
        "\n",
        "\n",
        "      #### save all items within object\n",
        "\n",
        "\n",
        "\n",
        "      # retrieve list of all items tagged\n",
        "\n",
        "      self.tagged_items_list = list(self.item_tax_df.index)\n",
        "\n",
        "\n",
        "      #intiate classes needed in remainder here\n",
        "      self.user_profiler = UserProfile(self.user_id, self.user_df, self.item_tag_df,  self.item_des_df, self.item_tax_df ,self.user_id_interaction_df)\n",
        "      self.weightedsims = WeighedItemSimilarity(self.item_des_df, self.item_tax_df , self.w_tfidf, self.w_tax) # this is object to avoid recalculations\n",
        "      self.recstart = UserIdPreferenceElictation(self.user_id , self.user_df, self.item_tag_df, self.full_item_df) # this is intiial preference elicitation\n",
        "\n",
        "      # retrieve ranked and positive items\n",
        "      self.ranked_items = self.user_profiler.retrieve_ranked_items()\n",
        "      self.positive_items = self.user_profiler.retrieve_positive_items()\n",
        "\n",
        "    def determine_user_type (self):\n",
        "      self.interaction_history = self.user_id_interaction_df.loc[self.user_id]\n",
        "      # we only include interactions with tagged items here as otherweise tells us nothing\n",
        "      valid_interactions = []\n",
        "      for item in list(self.interaction_history['item']):\n",
        "        if item in list(self.item_tax_df.index):\n",
        "          valid_interactions.append(item)\n",
        "\n",
        "      unique_valid_interactions = list(set(valid_interactions))\n",
        "      self.interaction_length = len(unique_valid_interactions)\n",
        "      if self.interaction_length > 19 : # arbitrary for now, can be optimized\n",
        "          self.user_type = 'Old'\n",
        "      else: self.user_type = 'New'\n",
        "      return self.user_type\n",
        "\n",
        "    def all_item_weighed_sim_scores(self):\n",
        "      self.all_weighed_sim_scores = self.weightedsims.all_weighed_sim_score\n",
        "      return  self.all_weighed_sim_scores\n",
        "\n",
        "\n",
        "    def sorted_item_weighed_score_and_ids(self, item_id):  # this is faster if only looking for one item\n",
        "      weighed_sim_score = self.weightedsims.weighed_sim_scorer(item_id)\n",
        "\n",
        "      item_indices = [i[0] for i in weighed_sim_score]\n",
        "\n",
        "      self.sorted_reccs = unpack_unique_reccs(self.item_tax_df.iloc[item_indices].index)\n",
        "\n",
        "      return  self.weighed_sim_score , self.sorted_reccs\n",
        "\n",
        "    def retrieve_most_sim_to_liked (self):\n",
        "        # retrieve list of all items tagged\n",
        "\n",
        "        self.tagged_items_list = list(self.item_tax_df.index)\n",
        "        most_sim_2_likes = []\n",
        "        n_sim_likes = 2\n",
        "        for item in self.positive_items:\n",
        "          if item in self.tagged_items_list: # unfortunately not the case for most which is why not working\n",
        "            reccs =  self.weightedsims.find_n_most_similar_items(item, n_sim_likes)\n",
        "            most_sim_2_likes.append(reccs)\n",
        "        self.most_sim_2_likes =  flatten(most_sim_2_likes)\n",
        "        return self.most_sim_2_likes\n",
        "\n",
        "\n",
        "\n",
        "    def reccomend(self, n_reccs):\n",
        "      self.user_type = self.determine_user_type()\n",
        "      self.n_reccs = n_reccs\n",
        "      if self.user_type == 'New':\n",
        "          self.recc_items = self.recstart.generate_initial_items()\n",
        "      else:\n",
        "        # first retrieve most similar to likes\n",
        "          self.reccs_from_likes = self.retrieve_most_sim_to_liked()\n",
        "          # now we calculate item scores and affinity to features\n",
        "          self.scores_by_item, self.scores = self.user_profiler.calculate_all_item_scores() # this can be avoided using weighed from above but no time to fix now, look at this for final\n",
        "          self.scores_sorted = [x for _,x in sorted(zip(self.scores,item_ids), reverse=True)]\n",
        "          self.reccs_from_tags = self.scores_sorted[1:self.n_reccs]\n",
        "          self.recc_items = self.reccs_from_likes + self.reccs_from_tags\n",
        "\n",
        "###### filter out any items already seen in case this was missed elsewhere ######\n",
        "\n",
        "      unseen_recc_items = []\n",
        "      for item in self.recc_items:\n",
        "        if item not in self.ranked_items:\n",
        "          unseen_recc_items.append(item)\n",
        "\n",
        "      self.recc_items = self.recc_items\n",
        "      self.unseen_recc_items = unseen_recc_items\n",
        "      return self.unseen_recc_items\n",
        "\n",
        "    def recc_gallery(self, n_reccs):\n",
        "        image_urls =[]\n",
        "        self.n_reccs =n_reccs\n",
        "        item_list = self.reccomend( self.n_reccs)\n",
        "        for item_id in item_list:\n",
        "          item = find_item(item_id)\n",
        "          image_urls.append(item['header_img'])\n",
        "        return gallery(image_urls, '200px')\n",
        "\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLDSHkPN4Uzb"
      },
      "source": [
        "As we gather data, we can refine these weights based on the performance metrics determined and then eventually switch to a deep learning model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "LtAsnvLYzjeC",
        "outputId": "98c20c70-b834-4f0a-9b37-36481c0b94b6"
      },
      "source": [
        "random_test_user = random.choice(new_users) # then old user at random\n",
        "w_tfidf = .2 # weight assigned to tfidf score in similarity computations\n",
        "w_tags = .8 # weight assigned to tag based item similarity from our taxonomy\n",
        "update_interactions = False # whether or not to update interactions for item tag scores\n",
        "update_items = False\n",
        "user_reccomender = FinalToteCBReccomenderDriveItem(random_test_user, update_interactions,update_items, root_dir, w_tfidf, w_tags)\n",
        "#user_reccomender.reccomend(20)\n",
        "user_reccomender.recc_gallery(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/j/a/jackwolfskin-1504741_5100-dk-moss__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/a/canadell-m5685_z0q-a-navy__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1772161_011-shark__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/w/h/white-sp0408011_ivr-bright-whi__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/o/northfac-nf0a4aon_0c5-a-grey__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1642061_010-black__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-bv5594_085-s-grey__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1654323_010-black__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1865171_023-city-grey__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/o/r/orcdn-269221_0001-black__s19__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/a/canadell-gt949-y08160_z0q-a-navy__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1884371_019__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/s/p/spyderac-194068_001-black__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/n/i/nike-bv0261_100-white__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/s/m/smartwoo-sw019046_a53-charcoal__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/1/1/11570935-60134_navy__01.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "            <figure style=\"margin: 5px !important;\">\n",
              "              <img src=\"http://www.sail.ca/media/catalog/product/c/o/columbia-1905794_191-chalk__01m.jpg\" style=\"height: 200px\">\n",
              "            </figure>\n",
              "        \n",
              "        </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asYtKLIIymAt"
      },
      "source": [
        "# Create sparse embeddings matrix for ALL ITEMS (noy just tagged)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51mjM9v-zyKH"
      },
      "source": [
        "untagged_item_tax_df = pd.DataFrame(np.zeros((len(untagged_items), len(list(item_tax_df.columns))),dtype=int), index = untagged_items , columns = list(item_tax_df.columns))\n",
        "untagged_item_tax_df.index.name = 'item'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSCeN-n419bK"
      },
      "source": [
        "full_tax_df = pd.concat([item_tax_df, untagged_item_tax_df])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFobJ3_40bQd"
      },
      "source": [
        "full_tax_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDNEduJaL30F"
      },
      "source": [
        "#items = item_tax_df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqv1mCtt2cAx"
      },
      "source": [
        "items = full_tax_df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMqdBnU92ff0"
      },
      "source": [
        "items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vr1jU1k9yZZ"
      },
      "source": [
        "# TF implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiH1MoJPBISI"
      },
      "source": [
        "ratings_df = user_id_interaction_df.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hi9v92FDNUO"
      },
      "source": [
        "ratings_df.rename(columns={'action': 'rating', 'createdAt':'timestamp'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_kqeP-cDii9"
      },
      "source": [
        "ratings_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBYODiYnD7WM",
        "outputId": "9c2a48a3-adbd-4c1b-d011-a1451a041c00"
      },
      "source": [
        "# understand what's the maximum number of hold out portion should be\n",
        "## not applicable to us yet\n",
        "ratings_df.groupby('user_id').item.nunique().min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioP_aHp9GGju"
      },
      "source": [
        "# Utility to split the data into training and test sets.\n",
        "def split_dataframe(df, holdout_fraction=0.1):\n",
        "  \"\"\"Splits a DataFrame into training and test sets.\n",
        "  Args:\n",
        "    df: a dataframe.\n",
        "    holdout_fraction: fraction of dataframe rows to use in the test set.\n",
        "  Returns:\n",
        "    train: dataframe for training\n",
        "    test: dataframe for testing\n",
        "  \"\"\"\n",
        "  test = df.sample(frac=holdout_fraction, replace=False)\n",
        "  train = df[~df.index.isin(test.index)]\n",
        "  return train, test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bocfp-rVEmAR"
      },
      "source": [
        "df_train, df_test = split_dataframe(ratings_df, .1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKAYis7nGod8"
      },
      "source": [
        "def get_unique_count(df):\n",
        "    \"\"\"calculate unique user and movie counts\"\"\"\n",
        "    return df.user_id.nunique(), df.item.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLrRlbPaFbkv",
        "outputId": "2d691a7e-a764-4608-ad89-5b22dc261233"
      },
      "source": [
        "print('training set shape', get_unique_count(df_train))\n",
        "print('testing set shape', get_unique_count(df_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set shape (10, 32)\n",
            "testing set shape (9, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3G3lAaoMCy_"
      },
      "source": [
        "items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38BJXQUFMkTH"
      },
      "source": [
        "users_i = user_df.reset_index()\n",
        "users = users_i[['user_id' , 'country' , 'gender' , 'date_of_birth']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oz7T9YihMPqB"
      },
      "source": [
        "users"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS2N0Xs6PEu2"
      },
      "source": [
        "## convert dob to age column\n",
        "from datetime import date\n",
        "import datetime\n",
        "for i in range(len(users)):\n",
        "  if users['date_of_birth'].isnull()[i] == False:\n",
        "    db = ast.literal_eval(users.iloc[i]['date_of_birth'])['$date']\n",
        "    #print(db)\n",
        "    users['date_of_birth'][i] = db\n",
        "  else: users['date_of_birth'][i] = 'NaN'\n",
        "users = users\n",
        "\n",
        "for i in range(len(users)):\n",
        "  if users['date_of_birth'].isnull()[i] == False:\n",
        "    if  users['date_of_birth'][i] != 'NaN':\n",
        "      user_datetime = datetime.datetime.fromtimestamp(users.iloc[i]['date_of_birth']*1e-3)\n",
        "      born = user_datetime.year\n",
        "      users['date_of_birth'][i] = 2021- born\n",
        "users = users"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u81WEoJgVzlY",
        "outputId": "f796e4ad-994b-4f6f-b028-5c237e65375f"
      },
      "source": [
        "for i in range(len(users)):\n",
        "  if users['date_of_birth'].isnull()[i] == False:\n",
        "    if  users['date_of_birth'][i] != 'NaN':\n",
        "      user_datetime = datetime.datetime.fromtimestamp(users.iloc[i]['date_of_birth']*1e-3)\n",
        "      born = user_datetime.year\n",
        "      users['date_of_birth'][i] = 2021- born\n",
        "users = users"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wss_LhW0VjPL",
        "outputId": "2611734d-4f2a-453a-802a-f33306973ba6"
      },
      "source": [
        "users.rename(columns = {'date_of_birth': 'age'}, inplace = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKkeYmZZXpnL"
      },
      "source": [
        "users"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EZP_EaxG4_7",
        "outputId": "a3b4c68a-f632-429c-a8a6-7cbfe9c6cf2e"
      },
      "source": [
        "# number of unique user and number of unique item/movie\n",
        "n_user, n_item = get_unique_count(df_train)\n",
        "\n",
        "print(\"number of unique users\", n_user)\n",
        "print(\"number of unique items\", n_item)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique users 10\n",
            "number of unique items 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E45XLFPib6RN"
      },
      "source": [
        "items"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XcKo2fxHFod",
        "outputId": "a1c392b6-54aa-458d-a490-d4f27ec5247e"
      },
      "source": [
        "%store n_user\n",
        "%store n_item"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 'n_user' (int)\n",
            "Stored 'n_item' (int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfNKug8RcGu4",
        "outputId": "128158a7-c37d-4b1a-ecec-1166865d1b25"
      },
      "source": [
        "ratings_df[\"user_id\"] = ratings_df[\"user_id\"].apply(lambda x: str(x))\n",
        "ratings_df[\"item\"] = ratings_df[\"item\"].apply(lambda x: str(x))\n",
        "ratings_df[\"rating\"] = ratings_df[\"rating\"].apply(lambda x: float(x))\n",
        "users[\"user_id\"] = users[\"user_id\"].apply(lambda x: str(x))\n",
        "items[\"item\"] = items[\"item\"].apply(lambda x: str(x))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGoDogI5LpeJ"
      },
      "source": [
        "tote = ratings_df.merge(items, on = 'item')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "EPz59e7B5NrC",
        "outputId": "32f417ac-6f19-4772-ffa1-6ba92f7123c9"
      },
      "source": [
        "tote"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>rating</th>\n",
              "      <th>outerwear</th>\n",
              "      <th>bottoms</th>\n",
              "      <th>sleepwear</th>\n",
              "      <th>underwear</th>\n",
              "      <th>tops</th>\n",
              "      <th>dresses &amp; jumpsuits</th>\n",
              "      <th>olive</th>\n",
              "      <th>light pink</th>\n",
              "      <th>burgundy</th>\n",
              "      <th>yellow</th>\n",
              "      <th>light purple</th>\n",
              "      <th>burnt red</th>\n",
              "      <th>light gray</th>\n",
              "      <th>taupe</th>\n",
              "      <th>mustard</th>\n",
              "      <th>neon coral</th>\n",
              "      <th>neon purple</th>\n",
              "      <th>fuchsia</th>\n",
              "      <th>coral</th>\n",
              "      <th>dark brown</th>\n",
              "      <th>brown</th>\n",
              "      <th>rose gold</th>\n",
              "      <th>dark gray</th>\n",
              "      <th>orange</th>\n",
              "      <th>mint</th>\n",
              "      <th>beige</th>\n",
              "      <th>hematite</th>\n",
              "      <th>neon blue</th>\n",
              "      <th>green</th>\n",
              "      <th>purple</th>\n",
              "      <th>white</th>\n",
              "      <th>blue</th>\n",
              "      <th>pink</th>\n",
              "      <th>teal</th>\n",
              "      <th>neon lime</th>\n",
              "      <th>mauve</th>\n",
              "      <th>...</th>\n",
              "      <th>rounded</th>\n",
              "      <th>angled</th>\n",
              "      <th>traditional menswear collar</th>\n",
              "      <th>fold-over collar</th>\n",
              "      <th>stand collar</th>\n",
              "      <th>short button-down</th>\n",
              "      <th>long button-down</th>\n",
              "      <th>stain resistant</th>\n",
              "      <th>breathable</th>\n",
              "      <th>water resistant</th>\n",
              "      <th>waterproof</th>\n",
              "      <th>closure - buttons</th>\n",
              "      <th>closure - zippers</th>\n",
              "      <th>zipper</th>\n",
              "      <th>fly front</th>\n",
              "      <th>metal zipper</th>\n",
              "      <th>fly front zipper</th>\n",
              "      <th>welt</th>\n",
              "      <th>welt pocket with button</th>\n",
              "      <th>even lap zipper</th>\n",
              "      <th>hole button</th>\n",
              "      <th>snaps</th>\n",
              "      <th>covered button</th>\n",
              "      <th>polo</th>\n",
              "      <th>knit</th>\n",
              "      <th>fleece</th>\n",
              "      <th>spandex</th>\n",
              "      <th>mock turtleneck</th>\n",
              "      <th>high neck</th>\n",
              "      <th>turtleneck</th>\n",
              "      <th>bottle</th>\n",
              "      <th>imperial</th>\n",
              "      <th>stand-away</th>\n",
              "      <th>jersey</th>\n",
              "      <th>rib knit</th>\n",
              "      <th>u-shape</th>\n",
              "      <th>lined</th>\n",
              "      <th>boyshort</th>\n",
              "      <th>low leg</th>\n",
              "      <th>high leg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>60d4c275de93100017f054b4</td>\n",
              "      <td>5f29685f65f956545839d09a</td>\n",
              "      <td>1625380016029</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60d4c275de93100017f054b4</td>\n",
              "      <td>5f33000efc074a35b09eeadb</td>\n",
              "      <td>1625380020007</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60d4c275de93100017f054b4</td>\n",
              "      <td>60ac190268efbb12cc7a7a05</td>\n",
              "      <td>1626584513216</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>60d4c275de93100017f054b4</td>\n",
              "      <td>60ac190268efbb12cc7a7a05</td>\n",
              "      <td>1626584958680</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>60d4c275de93100017f054b4</td>\n",
              "      <td>60ac190268efbb12cc7a7a05</td>\n",
              "      <td>1626585090459</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>610a65aa9b980d02d8cac88b</td>\n",
              "      <td>5f33000efc074a35b09eec41</td>\n",
              "      <td>1631972298120</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>610a65aa9b980d02d8cac88b</td>\n",
              "      <td>5f33000efc074a35b09eec41</td>\n",
              "      <td>1631972479722</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>610a65aa9b980d02d8cac88b</td>\n",
              "      <td>5f33000efc074a35b09eec41</td>\n",
              "      <td>1632031265278</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>610a65aa9b980d02d8cac88b</td>\n",
              "      <td>5f33000efc074a35b09eec41</td>\n",
              "      <td>1632031421582</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>60e4a188df068b0015e57c0b</td>\n",
              "      <td>5f33000efc074a35b09eec41</td>\n",
              "      <td>1632214591159</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>224 rows × 256 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      user_id                      item  ...  low leg  high leg\n",
              "0    60d4c275de93100017f054b4  5f29685f65f956545839d09a  ...        0         0\n",
              "1    60d4c275de93100017f054b4  5f33000efc074a35b09eeadb  ...        0         0\n",
              "2    60d4c275de93100017f054b4  60ac190268efbb12cc7a7a05  ...        0         0\n",
              "3    60d4c275de93100017f054b4  60ac190268efbb12cc7a7a05  ...        0         0\n",
              "4    60d4c275de93100017f054b4  60ac190268efbb12cc7a7a05  ...        0         0\n",
              "..                        ...                       ...  ...      ...       ...\n",
              "219  610a65aa9b980d02d8cac88b  5f33000efc074a35b09eec41  ...        0         0\n",
              "220  610a65aa9b980d02d8cac88b  5f33000efc074a35b09eec41  ...        0         0\n",
              "221  610a65aa9b980d02d8cac88b  5f33000efc074a35b09eec41  ...        0         0\n",
              "222  610a65aa9b980d02d8cac88b  5f33000efc074a35b09eec41  ...        0         0\n",
              "223  60e4a188df068b0015e57c0b  5f33000efc074a35b09eec41  ...        0         0\n",
              "\n",
              "[224 rows x 256 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq_LduWr4zCb",
        "outputId": "d5e60c8e-ad14-4052-85ff-905d7c65dcca"
      },
      "source": [
        "tote.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'item', 'timestamp', 'rating', 'outerwear', 'bottoms',\n",
              "       'sleepwear', 'underwear', 'tops', 'dresses & jumpsuits',\n",
              "       ...\n",
              "       'bottle', 'imperial', 'stand-away', 'jersey', 'rib knit', 'u-shape',\n",
              "       'lined', 'boyshort', 'low leg', 'high leg'],\n",
              "      dtype='object', length=256)"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoIgugO48yOS"
      },
      "source": [
        "df_train, df_test = split_dataframe(tote, .1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21BRw0Ta86CS"
      },
      "source": [
        "ROW_COUNT = df_train.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8RsIwYq9TO6"
      },
      "source": [
        "EMBEDDING_SIZE = 32\n",
        "NUM_USERS = tote['user_id'].nunique()\n",
        "NUM_ITEMS = tote['item'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8lSa-tm9hfz"
      },
      "source": [
        "UNIQUE_ITEM_IDS = tote['item'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUsKjcKN98Rg"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import Normalizer , scale\n",
        "from sklearn.model_selection import GridSearchCV , KFold , cross_val_score\n",
        "from sklearn.metrics import mean_squared_log_error,mean_squared_error, r2_score,mean_absolute_error\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba19EgfN9ova"
      },
      "source": [
        "def EmbeddingRec(EMBEDDING_SIZE, NUM_ITEMS, NUM_USERS, ROW_COUNT):\n",
        "    movie_input = keras.Input(shape=(1,), name='item')\n",
        "\n",
        "    movie_emb = layers.Embedding(output_dim=EMBEDDING_SIZE, input_dim=NUM_ITEMS, input_length=ROW_COUNT, name='movie_emb')(movie_input)\n",
        "    movie_vec = layers.Flatten(name='FlattenMovie')(movie_emb)\n",
        "\n",
        "    movie_model = keras.Model(inputs=movie_input, outputs=movie_vec)\n",
        "\n",
        "    user_input = keras.Input(shape=(1,), name='user_id')\n",
        "\n",
        "    user_emb = layers.Embedding(output_dim=EMBEDDING_SIZE, input_dim=NUM_USERS, input_length=ROW_COUNT, name='user_emb')(user_input)\n",
        "    user_vec = layers.Flatten(name='FlattenUser')(user_emb)\n",
        "\n",
        "    user_model = keras.Model(inputs=user_input, outputs=user_vec)\n",
        "\n",
        "    merged = layers.Dot(name = 'dot_product', normalize = True, axes = 2)([movie_emb, user_emb])\n",
        "    merged_dropout = layers.Dropout(0.2)(merged)\n",
        "\n",
        "\n",
        "    dense_1 = layers.Dense(70,name='FullyConnected-1')(merged)\n",
        "    dropout_1 = layers.Dropout(0.2,name='Dropout_1')(dense_1)\n",
        "\n",
        "    dense_2 = layers.Dense(50,name='FullyConnected-2')(dropout_1)\n",
        "    dropout_2 = layers.Dropout(0.2,name='Dropout_2')(dense_2)\n",
        "\n",
        "    dense_3 = keras.layers.Dense(20,name='FullyConnected-3')(dropout_2)\n",
        "    dropout_3 = keras.layers.Dropout(0.2,name='Dropout_3')(dense_3)\n",
        "\n",
        "    dense_4 = keras.layers.Dense(10,name='FullyConnected-4', activation='relu')(dropout_3)\n",
        "\n",
        "    result = layers.Dense(1, name='result', activation=\"relu\") (dense_4)\n",
        "\n",
        "    adam = keras.optimizers.Adam(lr=0.001)\n",
        "    model = keras.Model([movie_input, user_input], result)\n",
        "    model.compile(optimizer=adam,loss= 'mean_absolute_error')\n",
        "    return model, movie_model, user_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIABeX_q-CaM",
        "outputId": "55149053-295c-4207-ca49-45ed5f9f7080"
      },
      "source": [
        "model, item_model, user_model = EmbeddingRec(EMBEDDING_SIZE, NUM_ITEMS, NUM_USERS, ROW_COUNT)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t98bBHFz_cwr",
        "outputId": "7e309659-7589-4e38-fdba-c7c20e09a3f6"
      },
      "source": [
        "df_train.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "user_id       object\n",
              "item          object\n",
              "timestamp      int64\n",
              "rating       float64\n",
              "outerwear      int64\n",
              "              ...   \n",
              "low leg        int64\n",
              "high leg       int64\n",
              "country      float64\n",
              "gender       float64\n",
              "age           object\n",
              "Length: 259, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 345
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1o5TDBn-MuF"
      },
      "source": [
        "train = df_train\n",
        "test = df_test\n",
        "history = model.fit([train.item, train.user_id],train.rating, batch_size=100,\n",
        "                              epochs =50, validation_data = ([test.item, test.user_id],test.rating),\n",
        "                              verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}