{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cesare-Caputo/Tote/blob/main/image_recognition_Article_Type.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCmHam8KekTe"
      },
      "source": [
        "1. Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iy9so4wHHDDC"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy\n",
        "import sys\n",
        "\n",
        "# # if __name__ == \"__main__\":\n",
        "\n",
        "# dict = {'Blouses': 0, #Set the name of each category and the corresponding label, the name needs to be consistent with the folder name\n",
        "#         'Cardigans': 1,\n",
        "#         'Coats':2,\n",
        "#         'Dresses':3,\n",
        "#         'Jackets':4,\n",
        "#         'Jeans':5,\n",
        "#         'Pants':6,\n",
        "#         'Parkas':7,\n",
        "#         'Polo':8,\n",
        "#         'Shirts':9,\n",
        "#         'Sweatshirts':10,\n",
        "#         'Shorts':11,\n",
        "#         'Skirts':12,\n",
        "#         'Sweaters':13,\n",
        "#         'Sweatpants':14,\n",
        "#         'T-shirts':15}\n",
        "# rate = 0.1       #Randomly draw 10% of the samples as the validation set\n",
        "# root = '/content/drive/My Drive/Article Type'\n",
        "\n",
        "# Trainlist = []\n",
        "# Testlist = []\n",
        "# alllist = []\n",
        "# index = 0\n",
        "# # max_num = 80000\n",
        "\n",
        "# for folder in dict:\n",
        "# #     img_list = [f for f in os.listdir(os.path.join(root, folder)) if not f.startswith('.')]\n",
        "#     for img in img_list:\n",
        "#         str0 = '%d\\t%s\\t%d\\n' % (index, os.path.join(folder, img), dict[folder])\n",
        "#         index += 1\n",
        "#         alllist.append(str0)\n",
        "\n",
        "# random.seed(100)\n",
        "# random.shuffle(alllist)\n",
        "\n",
        "# num = int(len(alllist) * rate)\n",
        "# Testlist = alllist[0:num]\n",
        "# Trainlist = alllist[num:]\n",
        "\n",
        "# Trainfile = open(\"/content/drive/My Drive/Article Type/train.txt\", \"w\")\n",
        "# for str1 in Trainlist:\n",
        "#     Trainfile.write(str1)\n",
        "# Trainfile.close()\n",
        "\n",
        "# Testfile = open(\"/content/drive/My Drive/Article Type/valid.txt\", \"w\")\n",
        "# for str1 in Testlist:\n",
        "#     Testfile.write(str1)\n",
        "# Testfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WElQHfAbhm3v"
      },
      "source": [
        "# import os\n",
        "# from PIL import Image\n",
        "# from torch.utils import data\n",
        "# import numpy as np\n",
        "# from torchvision import transforms as T\n",
        "# import torch\n",
        "\n",
        "\n",
        "# class Fahion(data.Dataset):\n",
        "\n",
        "#     def __init__(self, root, lists, transforms=None, train=True, test=False):\n",
        "\n",
        "#         self.test = test\n",
        "#         # imgs = [os.path.join(root, img) for img in os.listdir(root)]\n",
        "\n",
        "#         with open (lists, 'r') as f:\n",
        "#             lines = f.readlines()\n",
        "\n",
        "#         imgs = []\n",
        "#         labels = []\n",
        "\n",
        "#         for line in lines:\n",
        "#             imgs.append(os.path.join(root, line.split()[1]))\n",
        "#             labels.append(line.split()[2])\n",
        "\n",
        "#         self.imgs = imgs\n",
        "#         self.labels = labels\n",
        "\n",
        "#         if transforms is None:\n",
        "\n",
        "#             self.transforms = T.Compose([\n",
        "#                 # T.Resize(224),  # 缩放图片Zoom the image, keep the aspect ratio unchanged, the shortest side is 224 pixels\n",
        "#                 T.Resize((227, 227)),  # zoom Image to (h,w)\n",
        "#                 # T.RandomHorizontalFlip(), #水平翻转，注意不是所有图片都适合，比如车牌\n",
        "#                 # T.CenterCrop(224),  # 从图片中间切出224*224的图片\n",
        "#                 #T.RandomCrop(224),  #随机裁剪\n",
        "#                 T.ToTensor(),  # 将图片(Image)转成Tensor，归一化至[0, 1]\n",
        "#                 T.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])  # 标准化至[-1, 1]，规定均值和标准差\n",
        "#             ])\n",
        "#         else:\n",
        "#             self.transforms = transforms\n",
        "\n",
        "\n",
        "#     def __getitem__(self, index):\n",
        "#         \"\"\"\n",
        "#         一次返回一张图片的数据\n",
        "#         \"\"\"\n",
        "#         img_path = self.imgs[index]\n",
        "#         label = self.labels[index]\n",
        "#         data = Image.open(img_path)\n",
        "#         data = self.transforms(data)\n",
        "#         return data, label\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.imgs)\n",
        "\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "\n",
        "#     dataset = Fahion('/content/drive/My Drive/Article Type', '/content/drive/My Drive/Article Type/train.txt')\n",
        "#     img, label = dataset[0]  # 相当于调用dataset.__getitem__(0)\n",
        "#     # for img, label in dataset:\n",
        "#     #     print(img.size(), img.float().mean(), label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHMHmnHmgg3Q"
      },
      "source": [
        "2. Build DenseNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJvEUWLrgcux"
      },
      "source": [
        "\"\"\"\n",
        "\tThe Network Class\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class Dense_Block(nn.Module):\n",
        "\tdef __init__(self, in_channels):\n",
        "\t\tsuper(Dense_Block, self).__init__()\n",
        "\n",
        "\t\tself.relu = nn.ReLU(inplace = True)\n",
        "\t\tself.bn = nn.BatchNorm2d(num_features = in_channels)\n",
        "\n",
        "\t\tself.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
        "\t\tself.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
        "\t\tself.conv3 = nn.Conv2d(in_channels = 64, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
        "\t\t# self.conv4 = nn.Conv2d(in_channels = 96, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
        "\t\t# self.conv5 = nn.Conv2d(in_channels = 128, out_channels = 32, kernel_size = 3, stride = 1, padding = 1)\n",
        "##reduce convolution layer\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\tbn = self.bn(x)\n",
        "\t\tconv1 = self.relu(self.conv1(bn))\n",
        "\n",
        "\t\tconv2 = self.relu(self.conv2(conv1))\n",
        "\t\tc2_dense = self.relu(torch.cat([conv1, conv2], 1))\n",
        "\n",
        "\t\tconv3 = self.relu(self.conv3(c2_dense))\n",
        "\t\tc3_dense = self.relu(torch.cat([conv1, conv2, conv3], 1))\n",
        "\n",
        "\t\t# conv4 = self.relu(self.conv4(c3_dense))\n",
        "\t\t# c4_dense = self.relu(torch.cat([conv1, conv2, conv3, conv4], 1))\n",
        "\n",
        "\t\t# conv5 = self.relu(self.conv5(c4_dense))\n",
        "\t\t# c5_dense = self.relu(torch.cat([conv1, conv2, conv3, conv4, conv5], 1))\n",
        "\n",
        "\t\t# return c5_dense\n",
        "\t\treturn c3_dense\n",
        "\n",
        "\n",
        "class Transition_Layer(nn.Module):\n",
        "\tdef __init__(self, in_channels, out_channels):\n",
        "\t\tsuper(Transition_Layer, self).__init__()\n",
        "\n",
        "\t\tself.relu = nn.ReLU(inplace = True)\n",
        "\t\tself.bn = nn.BatchNorm2d(num_features = out_channels)\n",
        "\t\tself.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels, kernel_size = 1, bias = False)\n",
        "\t\tself.avg_pool = nn.AvgPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\n",
        "\t\tbn = self.bn(self.relu(self.conv(x)))\n",
        "\t\tout = self.avg_pool(bn)\n",
        "\n",
        "\t\treturn out\n",
        "\n",
        "\n",
        "class DenseNet(nn.Module):\n",
        "\tdef __init__(self, nr_classes):\n",
        "\t\tsuper(DenseNet, self).__init__()\n",
        "\n",
        "\t\tself.lowconv = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 7, padding = 3, bias = False)\n",
        "\t\tself.relu = nn.ReLU()\n",
        "\n",
        "\t\t# Make Dense Blocks\n",
        "\t\tself.denseblock1 = self._make_dense_block(Dense_Block, 64)\n",
        "\t\tself.denseblock2 = self._make_dense_block(Dense_Block, 128)\n",
        "\t\tself.denseblock3 = self._make_dense_block(Dense_Block, 128)\n",
        "\n",
        "\t\t# Make transition Layers\n",
        "\t\tself.transitionLayer1 = self._make_transition_layer(Transition_Layer, in_channels = 160, out_channels = 128)\n",
        "\t\tself.transitionLayer2 = self._make_transition_layer(Transition_Layer, in_channels = 160, out_channels = 128)\n",
        "\t\tself.transitionLayer3 = self._make_transition_layer(Transition_Layer, in_channels = 160, out_channels = 64)\n",
        "\n",
        "\t\t# Classifier\n",
        "\t\tself.bn = nn.BatchNorm2d(num_features = 64)\n",
        "\t#50176 , 512\n",
        "\t\tself.pre_classifier = nn.Linear(64*3*3, 512)\n",
        "\t\tself.classifier = nn.Linear(512, nr_classes)\n",
        "\n",
        "\tdef _make_dense_block(self, block, in_channels):\n",
        "\t\tlayers = []\n",
        "\t\tlayers.append(block(in_channels))\n",
        "\t\treturn nn.Sequential(*layers)\n",
        "\n",
        "\tdef _make_transition_layer(self, layer, in_channels, out_channels):\n",
        "\t\tmodules = []\n",
        "\t\tmodules.append(layer(in_channels, out_channels))\n",
        "\t\treturn nn.Sequential(*modules)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tout = self.relu(self.lowconv(x))\n",
        "\t\tprint(out.shape)\n",
        "\n",
        "\t\tout = self.denseblock1(out)\n",
        "\t\tout = self.transitionLayer1(out)\n",
        "\t\tprint(out.shape)\n",
        "\n",
        "\t\tout = self.denseblock2(out)\n",
        "\t\tout = self.transitionLayer2(out)\n",
        "\t\tprint(out.shape)\n",
        "\n",
        "\t\tout = self.denseblock3(out)\n",
        "\t\tout = self.transitionLayer3(out)\n",
        "\t\tprint(out.shape)\n",
        "\n",
        "\t\tout = self.bn(out)\n",
        "\t\tout = out.view(out.shape[0], -1)\n",
        "\t\tprint(out.shape)\n",
        "\n",
        "\t\tout = self.pre_classifier(out)\n",
        "\t\tout = self.classifier(out)\n",
        "\n",
        "\t\treturn out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUu69PY84ENV",
        "outputId": "a82dfb50-9309-4908-8288-1a42cb95ddb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "out1 = densenet.lowconv(inputs)\n",
        "print(out1.shape)\n",
        "# out2 = densenet.denseblock1(out1)\n",
        "# print(out2.shape)\n",
        "# out3 = densenet.transitionLayer1(out2)\n",
        "# print(out3.shape)\n",
        "# out4 = densenet.denseblock2(out3)\n",
        "# print(out3.shape)\n",
        "# out5 = densenet.transitionLayer2(out4)\n",
        "# print(out4.shape)\n",
        "# out6 = densenet.denseblock3(out5)\n",
        "# print(out5.shape)\n",
        "# out6 = densenet.transitionLayer3(out6)\n",
        "# print(out6.shape)\n",
        "# out7 = densenet.bn(out6)\n",
        "# print(out7.shape)\n",
        "# out8 = out7.view(out7.shape[0], -1)\n",
        "# print(out8.shape)\n",
        "# out9 = densenet.pre_classifier(out8)\n",
        "# print(out9.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4fc9e119a171>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensenet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# out2 = densenet.denseblock1(out1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(out2.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# out3 = densenet.transitionLayer1(out2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'densenet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrF_3LA8OeDg"
      },
      "source": [
        "3. Import and preprocess dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOSGECDs7itt",
        "outputId": "7763c756-0551-4cf0-ff33-291169171dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "source": [
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "data_transforms = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "dataset = torchvision.datasets.ImageFolder('/content/drive/My Drive/intern_data',data_transforms)\n",
        "\n",
        "\n",
        "\n",
        "train_set, val_set = torch.utils.data.random_split(dataset, [10000, 2145])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-680d7e3383ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     ])\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/intern_data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m     92\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m     93\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mNo\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/intern_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJAHhOERD2lV",
        "outputId": "8ca8826b-2588-42b8-dfcc-d5a9afb5c6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdQRoGTehm5",
        "outputId": "c9e66805-bcc8-4470-c53d-02ac7ee7ec6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "import time\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "# from dataset import Fashion\n",
        "import argparse\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
        "                                            batch_size=batch_size,\n",
        "                                            shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=val_set,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d73c03567a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m train_loader = torch.utils.data.DataLoader(dataset=train_set,\n\u001b[0m\u001b[1;32m     16\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                             shuffle=True)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybR4mugXPKvR"
      },
      "source": [
        "4. Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APhsXLMtO490"
      },
      "source": [
        "import time\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 16\n",
        "momentum = 0.95\n",
        "learning_rate = 0.001\n",
        "nr_classes = 10\n",
        "nr_epochs = 10\n",
        "loss_vctr = []\n",
        "\n",
        "# Load the model on the GPU\n",
        "densenet = DenseNet(nr_classes)\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "  densenet.cuda()\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# Oprimization Criteria and Optimization method\n",
        "criterion = nn.CrossEntropyLoss().cuda() if use_gpu else nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(densenet.parameters(), lr=learning_rate, momentum=momentum, nesterov = False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ArtfQhXQ0TP",
        "outputId": "2cea6578-b031-4bc5-d8a1-3a50a5d76aff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Aug 12 14:34:48 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.57       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    27W /  70W |   5409MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM2WvMh7Qkig"
      },
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eWMnLPDPNzN"
      },
      "source": [
        "5. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76dL7ZbRPIon",
        "outputId": "1aa12fd7-8cf3-4868-8f0e-75769d48dd0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "print(\"Start of the Optimization Processs..\")\n",
        "for epoch in range(nr_epochs):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs = Variable(inputs).cuda()\n",
        "        labels = Variable(labels).cuda()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = densenet(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            loss_vctr.append(running_loss / 2000)\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print(\"^^^^^^^^^^^^^^^^^\")\n",
        "print('Finished Optimization.')\n",
        "end = time.time() # Time counted in seconds\n",
        "print(\"The total time to train the model on the K80 GPU is : {:.1f} minutes.\".format((end - start)/60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of the Optimization Processs..\n",
            "torch.Size([16, 50176])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-92056884041b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdensenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FtTPzvhPZzE"
      },
      "source": [
        "class_correct = list(0. for i in range(16))\n",
        "class_total = list(0. for i in range(16))\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = densenet(images.cuda())\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted.cpu() == labels).squeeze()\n",
        "        for i in range(16):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(16):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}